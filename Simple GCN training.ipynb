{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MARA - IMDB_mlh dataset tests - by Bartosz Trojan\n",
    "The implementation will be based on the official MARA paper\n",
    "Right now I don't have much to show, but this notebook will be updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zF5bw3m9UrMy",
    "outputId": "c9d66c9b-16c8-4b53-9e39-ec9f4530ed22"
   },
   "outputs": [],
   "source": [
    "# os.environ['TORCH'] = torch.__version__\n",
    "# print(torch.__version__)\n",
    "\n",
    "# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lewy700/Documents/MARA/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5614, 1000])\n",
      "torch.Size([5614])\n",
      "IMDB movie type dataset:\n",
      " Number of nodes: 5614\n",
      " Number of edges: 14715\n",
      " Number of edges: layer1: 5443, layer2: 3658, cross_layer: 5614\n",
      " Number of features: 1000\n",
      " Number of classes: 3\n",
      " Number of nodes per class: tensor([ 640, 2438, 2536])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "from utils.read_data_new import IMDB_mlh\n",
    "\n",
    "imdb = IMDB_mlh()\n",
    "imdb.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AkQAVluLuxT_",
    "outputId": "fec9f0d9-8c17-46e0-a2fa-92c75203c180"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'IMDB_mlh' object has no attribute 'num_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m         out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(h))\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out, h\n\u001b[0;32m---> 23\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mGCN\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m, in \u001b[0;36mGCN.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m1234\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1 \u001b[38;5;241m=\u001b[39m GCNConv(\u001b[43mimdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_features\u001b[49m, \u001b[38;5;241m512\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2 \u001b[38;5;241m=\u001b[39m GCNConv(\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m256\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3 \u001b[38;5;241m=\u001b[39m GCNConv(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m52\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'IMDB_mlh' object has no attribute 'num_features'"
     ]
    }
   ],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234)\n",
    "        self.conv1 = GCNConv(imdb.get_number_of_features(), 512)\n",
    "        self.conv2 = GCNConv(512, 256)\n",
    "        self.conv3 = GCNConv(256, 52)\n",
    "        self.classifier = Linear(52, imdb.get_number_of_classes())\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv3(h, edge_index)\n",
    "        h = h.tanh()  # Final GNN embedding space.\n",
    "\n",
    "        # Apply a final (linear) classifier.\n",
    "        out = torch.sigmoid(self.classifier(h))\n",
    "\n",
    "        return out, h\n",
    "\n",
    "model = GCN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "nwHtX5siwe2v",
    "outputId": "f784ae4a-9cac-4380-cf61-de02029f3117"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2807, 3])\n",
      "torch.Size([2807, 52])\n"
     ]
    }
   ],
   "source": [
    "model = GCN()\n",
    "\n",
    "out, h = model(imdb.node_features, imdb.layer_1.t())\n",
    "\n",
    "print(out.shape)\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tymczasowo dla przyśpieszenia testów\n",
    "\n",
    "from config import config\n",
    "import torch\n",
    "\n",
    "class MARA():\n",
    "    def __init__(self, simplificaton_type=config[\"simplification_type\"], simplification_stages=config[\"simplification_stages\"], simplification_strategy=config[\"simplification_strategy\"], DE_p=config[\"DE_p\"], NS_k=config[\"NS_k\"]):\n",
    "        self.simplification_type = simplificaton_type\n",
    "        self.simplification_stages = simplification_stages\n",
    "        self.simplification_strategy = simplification_strategy\n",
    "        self.DE_p = DE_p\n",
    "        self.NS_k = NS_k\n",
    "\n",
    "    def simplify(self, nodes_for_each_layer, edges_for_each_layer, cross_layer_edges, node_classes):\n",
    "        if(self.simplification_strategy == \"DE\"):\n",
    "            if(self.simplification_type == \"l-b-l\"):\n",
    "                simplified = []\n",
    "                for layer in range(len(edges_for_each_layer)):\n",
    "                    print(edges_for_each_layer[layer].shape)\n",
    "                    mask = torch.rand(1, edges_for_each_layer[layer].shape[0]) > self.DE_p\n",
    "                    simplified.append(edges_for_each_layer[layer][mask.squeeze()].clone())\n",
    "                    print(simplified[layer].shape)\n",
    "                return simplified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5443, 2])\n",
      "torch.Size([4366, 2])\n",
      "torch.Size([3658, 2])\n",
      "torch.Size([2901, 2])\n"
     ]
    }
   ],
   "source": [
    "mara = MARA()\n",
    "\n",
    "siplified_edges = mara.simplify(imdb.node_features, [imdb.layer_1, imdb.layer_2], [], imdb.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "etxOsz8QIbMO",
    "outputId": "466bf583-72a0-435a-9664-5d2cd6e35b0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========  10  ========\n",
      "Loss: 0.8080915808677673\n",
      "Accuracy: 0.7692307829856873\n",
      "========  20  ========\n",
      "Loss: 0.7790372371673584\n",
      "Accuracy: 0.7760055661201477\n",
      "========  30  ========\n",
      "Loss: 0.7441185116767883\n",
      "Accuracy: 0.807666003704071\n",
      "========  40  ========\n",
      "Loss: 0.7488386034965515\n",
      "Accuracy: 0.8007042407989502\n",
      "========  50  ========\n",
      "Loss: 0.7199681401252747\n",
      "Accuracy: 0.8195804357528687\n",
      "========  60  ========\n",
      "Loss: 0.7107707858085632\n",
      "Accuracy: 0.8474830985069275\n",
      "========  70  ========\n",
      "Loss: 0.7006860375404358\n",
      "Accuracy: 0.8562091588973999\n",
      "========  80  ========\n",
      "Loss: 0.6927056312561035\n",
      "Accuracy: 0.8596127033233643\n",
      "========  90  ========\n",
      "Loss: 0.690304696559906\n",
      "Accuracy: 0.8615494966506958\n",
      "========  100  ========\n",
      "Loss: 0.6872328519821167\n",
      "Accuracy: 0.8568249344825745\n",
      "========  110  ========\n",
      "Loss: 0.6731147766113281\n",
      "Accuracy: 0.875\n",
      "========  120  ========\n",
      "Loss: 0.685964047908783\n",
      "Accuracy: 0.8640287518501282\n",
      "========  130  ========\n",
      "Loss: 0.6952534317970276\n",
      "Accuracy: 0.8538135886192322\n",
      "========  140  ========\n",
      "Loss: 0.6806227564811707\n",
      "Accuracy: 0.8711302876472473\n",
      "========  150  ========\n",
      "Loss: 0.6810298562049866\n",
      "Accuracy: 0.8672817349433899\n",
      "========  160  ========\n",
      "Loss: 0.6812463402748108\n",
      "Accuracy: 0.8690476417541504\n",
      "========  170  ========\n",
      "Loss: 0.6749157309532166\n",
      "Accuracy: 0.8720608353614807\n",
      "========  180  ========\n",
      "Loss: 0.681624710559845\n",
      "Accuracy: 0.8650619983673096\n",
      "========  190  ========\n",
      "Loss: 0.682450532913208\n",
      "Accuracy: 0.8619505763053894\n",
      "========  200  ========\n",
      "Loss: 0.6773983836174011\n",
      "Accuracy: 0.8722807168960571\n"
     ]
    }
   ],
   "source": [
    "model = GCN()\n",
    "criterion = torch.nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01) \n",
    "\n",
    "def accuracy(preds, labels):\n",
    "    predicted_labels = torch.argmax(preds, dim=1)\n",
    "    accuracy = (predicted_labels == labels).float().mean()\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "def train(data):\n",
    "    optimizer.zero_grad()\n",
    "    out, h = model(data.node_features, data.layer_1.t()) \n",
    "    train_mask = data.get_training_mask(mask_size=0.5)\n",
    "\n",
    "    loss = criterion(out[train_mask], data.classes[train_mask])\n",
    "    acc = accuracy(out[train_mask], data.classes[train_mask])\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss, acc\n",
    "\n",
    "for epoch in range(201):\n",
    "    loss, acc = train(imdb)\n",
    "    if (epoch+1)%10 == 0:\n",
    "        print(\"======== \",epoch+1,\" ========\")\n",
    "        print(f\"Loss: {loss}\")\n",
    "        print(f\"Accuracy: {acc}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
