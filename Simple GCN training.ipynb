{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MARA - IMDB_mlh dataset tests - by Bartosz Trojan\n",
    "The implementation will be based on the official MARA paper\n",
    "Right now I don't have much to show, but this notebook will be updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zF5bw3m9UrMy",
    "outputId": "c9d66c9b-16c8-4b53-9e39-ec9f4530ed22"
   },
   "outputs": [],
   "source": [
    "# os.environ['TORCH'] = torch.__version__\n",
    "# print(torch.__version__)\n",
    "\n",
    "# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lewy700/Documents/MARA/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB movie type dataset:\n",
      " Number of nodes: 5614\n",
      " Number of edges: 14715\n",
      " Number of edges: layer1: 5443, layer2: 3658, cross_layer: 5614\n",
      " Number of features: 1000\n",
      " Number of classes: 3\n",
      " Number of nodes per class: tensor([ 640, 2438, 2536])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "from utils.read_data_new import IMDB_mlh\n",
    "from config import config\n",
    "\n",
    "imdb = IMDB_mlh()\n",
    "imdb.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropEdge(nn.Module):\n",
    "    def __init__(self, simplification_type=\"l-b-l\", p=0.2):\n",
    "        super().__init__()\n",
    "        self.simplification_type = simplification_type\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, edges, layers_lengths):\n",
    "        if(self.simplification_type == \"l-b-l\"):\n",
    "            intra_layers_length = torch.sum(layers_lengths[:-1])\n",
    "            intra_mask = torch.rand(intra_layers_length) > self.p\n",
    "\n",
    "            intra_layers = edges[:,:intra_layers_length]\n",
    "            edges = torch.cat([intra_layers[:,intra_mask], edges[:,intra_layers_length:]], dim=1)\n",
    "\n",
    "            new_layers_lenghts = []\n",
    "            temp = 0\n",
    "            for i in range(len(layers_lengths)-1):\n",
    "                new_layers_lenghts.append(torch.sum(intra_mask[temp:temp + layers_lengths[i]]))\n",
    "                temp += layers_lengths[i]\n",
    "            new_layers_lenghts.append(layers_lengths[-1])\n",
    "\n",
    "            return edges, torch.tensor(new_layers_lenghts)\n",
    "        \n",
    "        if(self.simplification_type == \"multilayer\"):\n",
    "            mask = torch.rand(edges.shape[1]) > self.p\n",
    "            edges = edges[:, mask]\n",
    "\n",
    "            new_layers_lenghts = []\n",
    "            temp = 0\n",
    "            for i in range(len(layers_lengths)):\n",
    "                new_layers_lenghts.append(torch.sum(mask[temp:temp + layers_lengths[i]]))\n",
    "                temp += layers_lengths[i]\n",
    "\n",
    "            return edges, torch.tensor(new_layers_lenghts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AkQAVluLuxT_",
    "outputId": "fec9f0d9-8c17-46e0-a2fa-92c75203c180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARA(\n",
      "  (conv1): GCNConv(1000, 512)\n",
      "  (conv2): GCNConv(512, 256)\n",
      "  (conv3): GCNConv(256, 52)\n",
      "  (classifier): Linear(in_features=52, out_features=3, bias=True)\n",
      "  (dropedge): DropEdge()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Dlaczego oni nie wspominają o żadnych funkcjach aktywacji w MARZE???\n",
    "\n",
    "class MARA(nn.Module):\n",
    "    def __init__(self, simplificaton_type=config[\"simplification_type\"], simplification_stages=config[\"simplification_stages\"], simplification_strategy=config[\"simplification_strategy\"], DE_p=config[\"DE_p\"], NS_k=config[\"NS_k\"]):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234)\n",
    "        \n",
    "        self.simplification_type = simplificaton_type\n",
    "        self.simplification_stages = simplification_stages\n",
    "        self.simplification_strategy = simplification_strategy\n",
    "        self.DE_p = DE_p\n",
    "        self.NS_k = NS_k\n",
    "        \n",
    "        self.conv1 = GCNConv(imdb.get_number_of_features(), 512)\n",
    "        self.conv2 = GCNConv(512, 256)\n",
    "        self.conv3 = GCNConv(256, 52)\n",
    "        self.classifier = nn.Linear(52, imdb.get_number_of_classes())\n",
    "\n",
    "        self.dropedge = DropEdge(self.simplification_type, self.DE_p)\n",
    "\n",
    "    def forward(self, x, edges, layers_lengths):\n",
    "        if self.simplification_stages == \"once\":\n",
    "            edges, layers_lengths = self.dropedge(edges, layers_lengths)\n",
    "            h = self.conv1(x, edges)\n",
    "            h = h.tanh()\n",
    "            h = self.conv2(h, edges)\n",
    "            h = h.tanh()\n",
    "            h = self.conv3(h, edges)\n",
    "            h = h.tanh()\n",
    "\n",
    "        if self.simplification_stages == \"each\":\n",
    "            edges, layers_lengths = self.dropedge(edges, layers_lengths)\n",
    "            h = self.conv1(x, edges)\n",
    "            h = h.tanh()\n",
    "            edges, layers_lengths = self.dropedge(edges, layers_lengths)\n",
    "            h = self.conv2(h, edges)\n",
    "            h = h.tanh()\n",
    "            edges, layers_lengths = self.dropedge(edges, layers_lengths)\n",
    "            h = self.conv3(h, edges)\n",
    "            h = h.tanh()\n",
    "\n",
    "        out = torch.sigmoid(self.classifier(h))\n",
    "\n",
    "        return out, h\n",
    "\n",
    "model = MARA()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "nwHtX5siwe2v",
    "outputId": "f784ae4a-9cac-4380-cf61-de02029f3117"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5614, 3])\n",
      "torch.Size([5614, 52])\n"
     ]
    }
   ],
   "source": [
    "model = MARA(simplification_stages=\"each\", simplification_strategy=\"l-b-l\", DE_p=0.2)\n",
    "\n",
    "out, h = model(imdb.node_features, torch.cat([imdb.layer_1, imdb.layer_2, imdb.cross_edges], dim=0).t(), torch.tensor([imdb.layer_1.shape[0], imdb.layer_2.shape[0], imdb.cross_edges.shape[0]]))\n",
    "\n",
    "print(out.shape)\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DropEdge(torch.autograd.Function):\n",
    "#     def __init__(self, simplification_type=\"l-b-l\", p=0.2):\n",
    "#         self.simplification_type = simplification_type\n",
    "#         self.p = p\n",
    "        \n",
    "#     @staticmethod\n",
    "#     def forward(ctx, intra_edges, cross_edges):\n",
    "#         if(ctx.simplification_type == \"l-b-l\"):\n",
    "#             mask = torch.rand(intra_edges.shape) > ctx.p\n",
    "#             ctx.save_for_backward(mask)\n",
    "\n",
    "#             return intra_edges[mask], cross_edges\n",
    "        \n",
    "#         if(ctx.simplification_type == \"multilayer\"):\n",
    "#             intra_mask = torch.rand(intra_edges.shape) > ctx.p\n",
    "#             cross_mask = torch.rand(cross_edges.shape) > ctx.p\n",
    "#             ctx.save_for_backward(intra_mask, cross_mask)\n",
    "\n",
    "#             return intra_edges[intra_mask], cross_edges[cross_mask]\n",
    "\n",
    "#     @staticmethod\n",
    "#     def backward(ctx, grad_output):\n",
    "#         if(ctx.simplification_type == \"l-b-l\"):\n",
    "#             mask = ctx.saved_tensors\n",
    "            \n",
    "#             return intra_edges[mask], cross_edges\n",
    "        \n",
    "#         if(ctx.simplification_type == \"multilayer\"):\n",
    "#             intra_mask = torch.rand(intra_edges.shape) > ctx.p\n",
    "#             cross_mask = torch.rand(cross_edges.shape) > ctx.p\n",
    "#             ctx.save_for_backward(intra_mask, cross_mask)\n",
    "\n",
    "#             return intra_edges[intra_mask], cross_edges[cross_mask]\n",
    "\n",
    "#         A = grad_output * D\n",
    "#         return A / (1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "etxOsz8QIbMO",
    "outputId": "466bf583-72a0-435a-9664-5d2cd6e35b0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training mask: 1388/5614\n",
      "========  10  ========\n",
      "Loss: 0.9788015484809875\n",
      "Train accuracy: 0.3394616678683009\n",
      "Test accuracy: 0.456143465909091\n",
      "========  20  ========\n",
      "Loss: 0.8850700855255127\n",
      "Train accuracy: 0.46250901225666907\n",
      "Test accuracy: 0.4436947601010101\n",
      "========  30  ========\n",
      "Loss: 0.7735413908958435\n",
      "Train accuracy: 0.5694544580629656\n",
      "Test accuracy: 0.6171480429292929\n",
      "========  40  ========\n",
      "Loss: 0.7031599283218384\n",
      "Train accuracy: 0.5382119682768566\n",
      "Test accuracy: 0.5650055239898991\n",
      "========  50  ========\n",
      "Loss: 0.6588013172149658\n",
      "Train accuracy: 0.5312424897861091\n",
      "Test accuracy: 0.5216619318181818\n",
      "========  60  ========\n",
      "Loss: 0.6335781216621399\n",
      "Train accuracy: 0.6516462388848835\n",
      "Test accuracy: 0.514599116161616\n",
      "========  70  ========\n",
      "Loss: 0.615115761756897\n",
      "Train accuracy: 0.6314587839461668\n",
      "Test accuracy: 0.5421796085858586\n",
      "========  80  ========\n",
      "Loss: 0.6028788089752197\n",
      "Train accuracy: 0.6675078106224465\n",
      "Test accuracy: 0.5617503156565656\n",
      "========  90  ========\n",
      "Loss: 0.5962444543838501\n",
      "Train accuracy: 0.666306176399904\n",
      "Test accuracy: 0.5618095012626263\n",
      "========  100  ========\n",
      "Loss: 0.5928220152854919\n",
      "Train accuracy: 0.6653448690218698\n",
      "Test accuracy: 0.5523398042929293\n",
      "========  110  ========\n",
      "Loss: 0.5873700380325317\n",
      "Train accuracy: 0.6646238884883441\n",
      "Test accuracy: 0.5454940025252526\n",
      "========  120  ========\n",
      "Loss: 0.5816237330436707\n",
      "Train accuracy: 0.6701514059120403\n",
      "Test accuracy: 0.5455729166666666\n",
      "========  130  ========\n",
      "Loss: 0.5761050581932068\n",
      "Train accuracy: 0.6768805575582792\n",
      "Test accuracy: 0.5387468434343434\n",
      "========  140  ========\n",
      "Loss: 0.574862539768219\n",
      "Train accuracy: 0.6792838260033646\n",
      "Test accuracy: 0.5230626578282829\n",
      "========  150  ========\n",
      "Loss: 0.5720831155776978\n",
      "Train accuracy: 0.6711127132900745\n",
      "Test accuracy: 0.5228653724747474\n",
      "========  160  ========\n",
      "Loss: 0.5704625844955444\n",
      "Train accuracy: 0.6739966354241768\n",
      "Test accuracy: 0.5194523358585859\n",
      "========  170  ========\n",
      "Loss: 0.5688197016716003\n",
      "Train accuracy: 0.6819274212929584\n",
      "Test accuracy: 0.5346827651515151\n",
      "========  180  ========\n",
      "Loss: 0.5665496587753296\n",
      "Train accuracy: 0.6857726508050949\n",
      "Test accuracy: 0.5416074810606061\n",
      "========  190  ========\n",
      "Loss: 0.5659435391426086\n",
      "Train accuracy: 0.6864936313386205\n",
      "Test accuracy: 0.5492621527777778\n",
      "========  200  ========\n",
      "Loss: 0.5650923848152161\n",
      "Train accuracy: 0.6879355924056716\n",
      "Test accuracy: 0.5475654987373738\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m layers_lengths \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([data\u001b[38;5;241m.\u001b[39mlayer_1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], data\u001b[38;5;241m.\u001b[39mlayer_2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], data\u001b[38;5;241m.\u001b[39mcross_edges\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m     44\u001b[0m out, h \u001b[38;5;241m=\u001b[39m model(data\u001b[38;5;241m.\u001b[39mnode_features, edges, layers_lengths) \n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal accuracy - whole dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, test_set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroc_auc_score(out[train_mask\u001b[38;5;250m \u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m],\u001b[38;5;250m \u001b[39mdata\u001b[38;5;241m.\u001b[39mclasses[train_mask\u001b[38;5;250m \u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/MARA/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/MARA/.venv/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:617\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    409\u001b[0m     {\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m     labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    429\u001b[0m ):\n\u001b[1;32m    430\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) \\\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m    from prediction scores.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;124;03m    array([0.81..., 0.84... , 0.93..., 0.87..., 0.94...])\u001b[39;00m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 617\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_true\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    619\u001b[0m     y_score \u001b[38;5;241m=\u001b[39m check_array(y_score, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/MARA/.venv/lib/python3.12/site-packages/sklearn/utils/multiclass.py:314\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse_pandas:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseSeries\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseArray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_multilabel\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# DeprecationWarning will be replaced by ValueError, see NEP 34\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# https://numpy.org/neps/nep-0034-infer-dtype-is-object.html\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;66;03m# We therefore catch both deprecation (NumPy < 1.24) warning and\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# value error (NumPy >= 1.24).\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/MARA/.venv/lib/python3.12/site-packages/sklearn/utils/multiclass.py:169\u001b[0m, in \u001b[0;36mis_multilabel\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    167\u001b[0m warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m, VisibleDeprecationWarning)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_y_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (VisibleDeprecationWarning, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/MARA/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1012\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1012\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m   1016\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/MARA/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:745\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    743\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 745\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[0;32m~/Documents/MARA/.venv/lib/python3.12/site-packages/torch/_tensor.py:1083\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "model = MARA()\n",
    "criterion = torch.nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01) \n",
    "\n",
    "def accuracy(preds, labels):\n",
    "    predicted_labels = torch.argmax(preds, dim=1)\n",
    "    accuracy = (predicted_labels == labels).float().mean()\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "train_mask = imdb.get_training_mask(mask_size=0.25)\n",
    "print(f\"training mask: {torch.sum(train_mask)}/{imdb.get_number_of_nodes()}\")\n",
    "\n",
    "def train(data):\n",
    "    optimizer.zero_grad()\n",
    "    edges = torch.cat([data.layer_1, data.layer_2, data.cross_edges], dim=0).t()\n",
    "    layers_lengths = torch.tensor([data.layer_1.shape[0], data.layer_2.shape[0], data.cross_edges.shape[0]], dtype=torch.int64)\n",
    "    out, h = model(data.node_features, edges, layers_lengths) \n",
    "\n",
    "    test_acc = accuracy(out[train_mask == False], imdb.classes[train_mask == False])\n",
    "\n",
    "    loss = criterion(out[train_mask], data.classes[train_mask])\n",
    "    acc = accuracy(out[train_mask], data.classes[train_mask])\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss, acc, test_acc\n",
    "\n",
    "for epoch in range(201):\n",
    "    loss, acc, test_acc = train(imdb)\n",
    "    if (epoch+1)%10 == 0:\n",
    "        print(\"======== \",epoch+1,\" ========\")\n",
    "        print(f\"Loss: {loss}\")\n",
    "        print(f\"Train accuracy: {acc}\")\n",
    "        print(f\"Test accuracy: {test_acc}\")\n",
    "data = imdb\n",
    "edges = torch.cat([data.layer_1, data.layer_2, data.cross_edges], dim=0).t()\n",
    "layers_lengths = torch.tensor([data.layer_1.shape[0], data.layer_2.shape[0], data.cross_edges.shape[0]], dtype=torch.int64)\n",
    "out, h = model(data.node_features, edges, layers_lengths) \n",
    "\n",
    "print(f\"Final accuracy - whole dataset: {accuracy(out, data.classes)}, test_set: {accuracy(out[train_mask == False], data.classes[train_mask == False])}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
